{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "\n",
                "photos = \"../data/raw/train/\"\n",
                "dog_photos = \"../data/raw/train/dog\"\n",
                "cat_photos = \"../data/raw/train/cat\" \n",
                "\n",
                "# Obtener las rutas de las primeras nueve imágenes de perros y gatos\n",
                "dogs_imgs = [os.path.join(dog_photos, img) for img in os.listdir(dog_photos)][:9]\n",
                "cats_imgs = [os.path.join(cat_photos, img) for img in os.listdir(cat_photos)][:9]\n",
                "\n",
                "# Función para mostrar las imágenes\n",
                "def show_images(images, title):\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    for i in range(9):\n",
                "        plt.subplot(3, 3, i + 1)\n",
                "        img = mpimg.imread(images[i])\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "    plt.suptitle(title)\n",
                "    plt.show()\n",
                "\n",
                "# Mostrar las primeras nueve imágenes de perros\n",
                "show_images(dogs_imgs, \"Primeras nueve imágenes de perros\")\n",
                "\n",
                "# Mostrar las primeras nueve imágenes de gatos\n",
                "show_images(cats_imgs, \"Primeras nueve imágenes de perros\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# Ruta al directorio principal que contiene los subdirectorios \"train\" y \"test\"\n",
                "all_photos = \"../data/raw/\"\n",
                "\n",
                "# Configuración de ImageDataGenerator para cargar imágenes progresivamente\n",
                "datagentrain = ImageDataGenerator()\n",
                "datagentest = ImageDataGenerator()\n",
                "\n",
                "# Generador de datos para las imágenes de train\n",
                "train_generator = datagentrain.flow_from_directory(\n",
                "    all_photos + \"train\",\n",
                "    target_size = (200, 200),\n",
                "    classes = [\"dog\", \"cat\"],\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")\n",
                "\n",
                "# Generador de datos para las imágenes de test\n",
                "test_generator = datagentest.flow_from_directory(\n",
                "    all_photos,\n",
                "    target_size = (200, 200),\n",
                "    classes = [\"test\"] \n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required modules\n",
                "import keras\n",
                "from keras.optimizers import Adam\n",
                "\n",
                "model.compile(loss = keras.losses.categorical_crossentropy, optimizer = Adam(learning_rate = 0.001), metrics = [\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.fit(train_generator, epochs = 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "checkpoint = ModelCheckpoint(\"../models/vgg16_1.h5\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\")\n",
                "early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, verbose = 1, mode = \"auto\")\n",
                "hist = model.fit(train_data, steps_per_epoch = 100, validation_data = test_data, validation_steps = 10, epochs = 3, callbacks = [checkpoint, early])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check the Accuracy of the Data\n",
                "\n",
                "#Plot the Results\n",
                "plt.plot(hist.history[\"accuracy\"])\n",
                "plt.plot(hist.history[\"val_accuracy\"])\n",
                "plt.plot(hist.history[\"loss\"])\n",
                "plt.plot(hist.history[\"val_loss\"])\n",
                "\n",
                "# Configure the Plot Layout\n",
                "plt.title(\"Model Accuracy\")\n",
                "plt.ylabel(\"Accuracy\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.legend([\"Accuracy\", \"Validation Accuracy\", \"Loss\", \"Validation Loss\"])\n",
                "\n",
                "# Plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.preprocessing import image\n",
                "from keras.models import load_model\n",
                "\n",
                "img = image.load_img(\"../data/raw/test/9.jpg\", target_size = (200, 200))\n",
                "img = np.asarray(img)\n",
                "plt.imshow(img)\n",
                "img = np.expand_dims(img, axis = 0)\n",
                "saved_model = load_model(\"../models/vgg16_1.h5\")\n",
                "output = saved_model.predict(img)\n",
                "if output[0][0] > output[0][1]:\n",
                "    print(\"cat\")\n",
                "else:\n",
                "    print(\"dog\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
